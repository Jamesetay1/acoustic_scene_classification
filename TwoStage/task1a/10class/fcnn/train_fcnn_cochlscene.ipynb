{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/user_data/jtaylor/home/.conda/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.optimizers import SGD\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "from funcs import *\n",
    "\n",
    "from fcnn_att import model_fcnn\n",
    "from DCASE_training_functions import *\n",
    "\n",
    "from tensorflow import ConfigProto\n",
    "from tensorflow import InteractiveSession\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "base_path = '/work/user_data/jtaylor/data/acoustic_scene_classification'\n",
    "train_csv = f'{base_path}/data/CochlScene/train_shuffled_20k.tsv'\n",
    "val_csv = f'{base_path}/data/CochlScene/val_shuffled_5k.tsv'\n",
    "\n",
    "# train_csv = f'{base_path}/data/CochlScene/train_shuffled_tiny.tsv'\n",
    "# val_csv = f'{base_path}/data/CochlScene/val_shuffled_tiny.tsv'\n",
    "\n",
    "feat_path = f'{base_path}/data/CochlScene/features/logmel128_scaled/'\n",
    "\n",
    "experiments = 'cochlscene_test/'\n",
    "\n",
    "if not os.path.exists(experiments):\n",
    "    os.makedirs(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of training samples: 19999\n",
      "4999 validation samples with values {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Counter({11: 403, 3: 396, 2: 394, 0: 393, 4: 392, 1: 390, 8: 385, 5: 381, 6: 379, 12: 377, 10: 375, 9: 369, 7: 365})\n",
      "\n",
      "validation data shape: (4999, 128, 431, 1)\n",
      "validation data deltas shape: (4999, 128, 427, 1)\n",
      "validation data delta deltas shape: (4999, 128, 427, 1)\n",
      "validation data concat shape: (4999, 128, 423, 3)\n"
     ]
    }
   ],
   "source": [
    "#train_aug_csv = generate_train_aug_csv(train_csv, aug_csv, feat_path, aug_path, experiments)\n",
    "train_aug_csv = train_csv\n",
    "\n",
    "num_audio_channels = 1\n",
    "num_freq_bin = 128\n",
    "num_classes = 13\n",
    "max_lr = 0.1\n",
    "batch_size = 64\n",
    "num_epochs = 250\n",
    "mixup_alpha = 0.4\n",
    "crop_length = 400\n",
    "sample_num = len(open(train_aug_csv, 'r').readlines()) - 1\n",
    "print(f'Numbers of training samples: {sample_num}')\n",
    "\n",
    "\n",
    "# compute delta and delta delta for validation data\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "print(f'{len(y_val)} validation samples with values {set(y_val)}')\n",
    "print(f'{collections.Counter(y_val)}\\n')\n",
    "print(f'validation data shape: {data_val.shape}')\n",
    "\n",
    "\n",
    "data_deltas_val = deltas(data_val)\n",
    "print(f'validation data deltas shape: {data_deltas_val.shape}')\n",
    "\n",
    "data_deltas_deltas_val = deltas(data_deltas_val)\n",
    "print(f'validation data delta deltas shape: {data_deltas_val.shape}')\n",
    "\n",
    "data_val = np.concatenate((data_val[:,:,4:-4,:],data_deltas_val[:,:,2:-2,:],data_deltas_deltas_val),axis=-1)\n",
    "print(f'validation data concat shape: {data_val.shape}')\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_fcnn(num_classes, input_shape=[num_freq_bin, None, 3*num_audio_channels], num_filters=[48, 96, 192], wd=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 128, None, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 128, None, 3) 12          input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, 132, None, 3) 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, None, 144 10800       zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 64, None, 144 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 64, None, 144 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, 66, None, 144 0           activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 64, None, 144 186624      zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 64, None, 144 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 64, None, 144 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 32, None, 144 0           activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67 (ZeroPadding2 (None, 34, None, 144 0           max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, None, 288 373248      zero_padding2d_67[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, None, 288 1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, None, 288 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 34, None, 288 0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, None, 288 746496      zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 32, None, 288 1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 32, None, 288 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 16, None, 288 0           activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_69 (ZeroPadding2 (None, 18, None, 288 0           max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, None, 576 1492992     zero_padding2d_69[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 16, None, 576 2304        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 16, None, 576 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, None, 576 0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_70 (ZeroPadding2 (None, 18, None, 576 0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, None, 576 2985984     zero_padding2d_70[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 16, None, 576 2304        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 16, None, 576 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 16, None, 576 0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_71 (ZeroPadding2 (None, 18, None, 576 0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, None, 576 2985984     zero_padding2d_71[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, None, 576 2304        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 16, None, 576 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16, None, 576 0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_72 (ZeroPadding2 (None, 18, None, 576 0           dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, None, 576 2985984     zero_padding2d_72[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, None, 576 2304        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 16, None, 576 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 8, None, 576) 0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, None, 13)  7488        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, None, 13)  26          conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, None, 13)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, None, 13)  26          activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_17 (Gl (None, 13)           0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_9 (GlobalM (None, 13)           0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 1, 13)     0           global_average_pooling2d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 1, 13)     0           global_max_pooling2d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1, 1, 6)      84          reshape_17[0][0]                 \n",
      "                                                                 reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1, 1, 13)     91          dense_17[0][0]                   \n",
      "                                                                 dense_17[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1, 1, 13)     0           dense_18[0][0]                   \n",
      "                                                                 dense_18[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1, 1, 13)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 8, None, 13)  0           batch_normalization_99[0][0]     \n",
      "                                                                 activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_18 (Gl (None, 13)           0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 13)           0           global_average_pooling2d_18[0][0]\n",
      "==================================================================================================\n",
      "Total params: 11,788,511\n",
      "Trainable params: 11,782,117\n",
      "Non-trainable params: 6,394\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer =SGD(lr=max_lr,decay=1e-6, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0]) \n",
    "save_path = experiments + \"/model-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "   2/2000 [..............................] - ETA: 2:24:14 - loss: 2.5626 - acc: 0.1000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/user_data/jtaylor/home/.conda/envs/d20-keras/lib/python3.6/site-packages/keras/callbacks.py:99: UserWarning: Method on_batch_begin() is slow compared to the batch update (0.982896). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 294/2000 [===>..........................] - ETA: 4:47 - loss: 2.5652 - acc: 0.0738"
     ]
    }
   ],
   "source": [
    "# Due to the memory limitation, in the training stage we split the training data\n",
    "train_data_generator = Generator_timefreqmask_withdelta_splitted(feat_path, train_aug_csv, num_freq_bin,\n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha,\n",
    "                              crop_length=crop_length, splitted_num=5, classes=num_classes)()\n",
    "\n",
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d20-keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
