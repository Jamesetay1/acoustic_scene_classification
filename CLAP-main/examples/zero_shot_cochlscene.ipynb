{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is an example using CLAP to perform zeroshot\n",
    "    classification on ESC50 (https://github.com/karolpiczak/ESC-50).\n",
    "\"\"\"\n",
    "\n",
    "from msclap import CLAP\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>scene_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kitchen/Kitchen_user0500_14825861_004.wav</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kitchen/Kitchen_user0365_14829983_000.wav</td>\n",
       "      <td>Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kitchen/Kitchen_user0445_14861824_000.wav</td>\n",
       "      <td>Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe/Cafe_user0159_14987442_005.wav</td>\n",
       "      <td>Cafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bus/Bus_user0138_14982391_008.wav</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Bus/Bus_user0530_14878229_004.wav</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>CrowdedIndoor/CrowdedIndoor_user0811_14981731_...</td>\n",
       "      <td>CrowdedIndoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>CrowdedIndoor/CrowdedIndoor_user0001_14876853_...</td>\n",
       "      <td>CrowdedIndoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Kitchen/Kitchen_user0585_14834807_000.wav</td>\n",
       "      <td>Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Street/Street_user0108_14840677_002.wav</td>\n",
       "      <td>Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename    scene_label\n",
       "0            Kitchen/Kitchen_user0500_14825861_004.wav            Car\n",
       "1            Kitchen/Kitchen_user0365_14829983_000.wav        Kitchen\n",
       "2            Kitchen/Kitchen_user0445_14861824_000.wav        Kitchen\n",
       "3                  Cafe/Cafe_user0159_14987442_005.wav           Cafe\n",
       "4                    Bus/Bus_user0138_14982391_008.wav            Bus\n",
       "..                                                 ...            ...\n",
       "226                  Bus/Bus_user0530_14878229_004.wav            Bus\n",
       "227  CrowdedIndoor/CrowdedIndoor_user0811_14981731_...  CrowdedIndoor\n",
       "228  CrowdedIndoor/CrowdedIndoor_user0001_14876853_...  CrowdedIndoor\n",
       "229          Kitchen/Kitchen_user0585_14834807_000.wav        Kitchen\n",
       "230            Street/Street_user0108_14840677_002.wav         Street\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Car': 0, 'Kitchen': 1, 'Cafe': 2, 'Bus': 3, 'ResidentialArea': 4, 'Restaurant': 5, 'Restroom': 6, 'Street': 7, 'CrowdedIndoor': 8, 'Subway': 9, 'SubwayStation': 10, 'Elevator': 11, 'Park': 12}\n",
      "['this is the sound of Car', 'this is the sound of Kitchen', 'this is the sound of Cafe', 'this is the sound of Bus', 'this is the sound of ResidentialArea', 'this is the sound of Restaurant', 'this is the sound of Restroom', 'this is the sound of Street', 'this is the sound of CrowdedIndoor', 'this is the sound of Subway', 'this is the sound of SubwayStation', 'this is the sound of Elevator', 'this is the sound of Park']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "root_path = \"/work/user_data/jtaylor/data/acoustic_scene_classification/data/CochlScene\"\n",
    "val_df = pd.read_csv(f'{root_path}/val_shuffled_tiny.tsv', sep='\\t')\n",
    "classes = val_df['scene_label'].unique()\n",
    "display(val_df)\n",
    "\n",
    "class_id_map = {name: i for i, name in enumerate(classes, 0)}\n",
    "print(class_id_map)\n",
    "\n",
    "prompt = 'this is the sound of '\n",
    "y = [prompt + x for x in classes]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialize CLAP\n",
    "clap_model = CLAP(version = '2023', use_cuda=False)\n",
    "\n",
    "# Computing text embeddings\n",
    "text_embeddings = clap_model.get_text_embeddings(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mounts/ud-data/jtaylor/a5f2c23d-7fb6-41a6-ac0c-3a2ffc02b992/data/acoustic_scene_classification/CLAP-main/examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [00:19<00:00, 11.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Computing audio embeddings\n",
    "y_preds, y_labels = [], []\n",
    "print(os.getcwd())\n",
    "\n",
    "for i in tqdm(range(len(val_df))):\n",
    "    path, label = val_df.iloc[i]\n",
    "    path = f'{root_path}/Val/{path}'\n",
    "    idx = class_id_map[label]\n",
    "    #print(idx)\n",
    "    one_hot_target = torch.nn.functional.one_hot(torch.tensor([idx]), num_classes=len(classes)+1)\n",
    "\n",
    "    audio_embeddings = clap_model.get_audio_embeddings([path], resample=True)\n",
    "    similarity = clap_model.compute_similarity(audio_embeddings, text_embeddings)\n",
    "\n",
    "    y_pred = F.softmax(similarity.detach().cpu(), dim=1).numpy()\n",
    "\n",
    "    y_preds.append(y_pred)\n",
    "    y_labels.append(one_hot_target.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.3342727e-06, 9.9877101e-01, 6.2616064e-06, 4.8860937e-07,\n",
      "        9.3500428e-05, 7.9232705e-05, 9.3976600e-04, 4.3500545e-06,\n",
      "        1.2932780e-05, 1.9139382e-07, 3.2675572e-07, 1.9265119e-05,\n",
      "        7.0437294e-05]], dtype=float32), array([[1.1373779e-05, 9.9446702e-01, 3.4023742e-05, 1.9009992e-06,\n",
      "        3.2453315e-04, 3.2638613e-04, 4.7429637e-03, 1.1701374e-05,\n",
      "        1.2022599e-06, 3.2149990e-07, 2.6058984e-07, 5.1041989e-05,\n",
      "        2.7247119e-05]], dtype=float32), array([[2.4114372e-06, 9.9098653e-01, 1.4744124e-04, 9.2183427e-07,\n",
      "        8.8739573e-05, 2.3134758e-03, 6.3867308e-03, 2.9005878e-06,\n",
      "        2.4908975e-06, 2.3651734e-07, 4.8722751e-07, 6.2111591e-05,\n",
      "        5.5750238e-06]], dtype=float32), array([[1.2702657e-05, 5.3329865e-04, 8.3285302e-01, 7.7392033e-05,\n",
      "        8.7633291e-03, 9.9677123e-02, 4.9501625e-03, 1.5035517e-03,\n",
      "        3.2160338e-03, 9.2121674e-04, 4.5314673e-02, 5.1669759e-04,\n",
      "        1.6607062e-03]], dtype=float32), array([[3.4716073e-02, 2.8094335e-04, 1.9197229e-04, 9.6146435e-01,\n",
      "        4.3127331e-04, 3.6402449e-05, 6.6808256e-04, 3.0195777e-04,\n",
      "        6.2400013e-06, 3.1361892e-04, 3.8566109e-06, 1.4965318e-03,\n",
      "        8.8687666e-05]], dtype=float32), array([[1.2857086e-04, 3.8454114e-04, 2.3809714e-04, 1.8878869e-05,\n",
      "        6.9956994e-01, 6.1047164e-04, 6.7213265e-04, 9.5796306e-03,\n",
      "        7.6541281e-03, 5.6401004e-06, 2.7557396e-04, 1.4746416e-04,\n",
      "        2.8071496e-01]], dtype=float32)]\n",
      "[array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "print(y_preds)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC50 Accuracy 0.8614718614718615\n"
     ]
    }
   ],
   "source": [
    "y_labels, y_preds = np.concatenate(y_labels, axis=0), np.concatenate(y_preds, axis=0)\n",
    "acc = accuracy_score(np.argmax(y_labels, axis=1), np.argmax(y_preds, axis=1))\n",
    "print('ESC50 Accuracy {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DCASE_ClassNames = ['airport', 'bus', 'metro', 'metro_station', 'park', 'public_square',\n",
    " 'shopping_mall', 'street_pedestrian', 'street_traffic', 'tram']\n",
    "\n",
    "# get confusion matrix\n",
    "conf_matrix = confusion_matrix(y_labels,y_preds)\n",
    "conf_matrix = np.delete(conf_matrix, np.s_[-3:], axis=1)\n",
    "conf_mat_norm_recall = conf_matrix.astype('float32')/conf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "recall_by_class = np.diagonal(conf_mat_norm_recall)\n",
    "mean_recall = np.mean(recall_by_class)\n",
    "\n",
    "# Calculate row sums to use for percentages\n",
    "row_sums = conf_matrix.sum(axis=1)\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = (conf_matrix.T / row_sums).T  # Transpose for division, then transpose back\n",
    "\n",
    "# Format percentages as strings with '%' symbol\n",
    "annot_data = [['{:.2f}'.format(val) for val in row] for row in percentages]\n",
    "annot_data = [['' if float(val <= 0.04) else '{:.2f}'.format(val) for val in row] for row in percentages]\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "\n",
    "annot_kws = {'size': 6}\n",
    "ax = sns.heatmap(percentages, xticklabels=DCASE_ClassNames, yticklabels=ClassNames, annot=annot_data, fmt='', square=True, cmap='Blues', annot_kws=annot_kws)\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "#plt.subplots_adjust(left=0.2, bottom=0.35)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clap-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
