{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "\n",
    "from trainer import Trainer\n",
    "import utils_funcs\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment outputs will be found at:  ./outdir/cp_resnet/exp_Nov06_12.59.49\n",
      "The experiment tesnorboard can be accessed: tensorboard --logdir   ./runsdir/cp_resnet/exp_Nov06_12.59.49\n",
      "Rho value :  5\n",
      "Use Mix-up :  1\n",
      "For this Rho, the maximium RF is:  81\n"
     ]
    }
   ],
   "source": [
    "epochs=400\n",
    "rho=5\n",
    "mixup=1\n",
    "load = None\n",
    "load='pretrained_models/single_resnet/last_model_300.pth'\n",
    "\n",
    "if load is None:\n",
    "    with open(\"configs/cp_resnet.json\", \"r\") as text_file:\n",
    "        default_conf = json.load(text_file)\n",
    "else:\n",
    "    with open(\"configs/cp_resnet_eval.json\", \"r\") as text_file:\n",
    "        default_conf = json.load(text_file)\n",
    "\n",
    "default_conf['out_dir'] = default_conf['out_dir'] + str(datetime.datetime.now().strftime('%b%d_%H.%M.%S'))\n",
    "\n",
    "print(\"The experiment outputs will be found at: \", default_conf['out_dir'])\n",
    "tensorboard_write_path = default_conf['out_dir'].replace(\"out\", \"runs\", 1)\n",
    "print(\"The experiment tesnorboard can be accessed: tensorboard --logdir  \", tensorboard_write_path)\n",
    "\n",
    "print(\"Rho value : \", rho)\n",
    "print(\"Use Mix-up : \", mixup)\n",
    "\n",
    "from models.cp_resnet import get_model_based_on_rho\n",
    "\n",
    "default_conf['model_config'] = get_model_based_on_rho(rho, config_only=True)\n",
    "\n",
    "# find the RF at the 24th layer of the model defined by this config\n",
    "# this equations are explained in:\n",
    "# The Receptive Field as a Regularizer in Deep Convolutional Neural Networks for Acoustic Scene Classification,\n",
    "# Koutini et al.\n",
    "# EUSIPCO 2019\n",
    "\n",
    "try:\n",
    "    # set utils_funcs.model_config to the current model (not safe with lru)\n",
    "    utils_funcs.model_config = default_conf['model_config']\n",
    "    _, max_rf = utils_funcs.get_maxrf(24)\n",
    "    print(\"For this Rho, the maximium RF is: \", max_rf)\n",
    "except:\n",
    "    print(\"couldn't determine the max RF, maybe non-standard model_config\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "if mixup:\n",
    "    default_conf['use_mixup'] = True\n",
    "    default_conf['loss_criterion'] = 'mixup_default'\n",
    "else:\n",
    "    default_conf['use_mixup'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "I: for detailed run info use \n",
      " \u001b[91mtail -f ./outdir/cp_resnet/exp_Nov06_12.59.49/info.log\u001b[0m\n",
      "I: tensorboard run path: ./runsdir/cp_resnet/exp_Nov06_12.59.49\n",
      "I: To monitor this experiment use:\n",
      " \u001b[91mtensorboard --logdir ./runsdir/cp_resnet/exp_Nov06_12.59.49\u001b[0m\n",
      "Network(\n",
      "  (in_c): Sequential(\n",
      "    (0): Conv2d(2, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (stage1): Sequential(\n",
      "    (block1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (maxpool1_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (block2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (maxpool2_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (block3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (block4): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (maxpool4_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (block1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (block3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (block4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (block1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (block3): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (block4): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (feed_forward): Sequential(\n",
      "    (0): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n",
      "I: \n",
      "\n",
      "Trainable model parameters 3566612, non-trainable 0 \n",
      "\n",
      "\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: [0.9, 0.999]\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "normalized test!\n",
      "loading dataset from 'd19t1'\n",
      "normalizing dataset\n",
      "attempting to load x from cache at datasets/cached_datasets/d19t1/tr_mean_452f8f_f1_apd18_stereo_obj.pt...\n",
      "loaded datasets/cached_datasets/d19t1/tr_mean_452f8f_f1_apd18_stereo_obj.pt from cache in 0.004163503646850586 \n",
      "attempting to load x from cache at datasets/cached_datasets/d19t1/tr_std_452f8f_f1_apd18_stereo_obj.pt...\n",
      "loaded datasets/cached_datasets/d19t1/tr_std_452f8f_f1_apd18_stereo_obj.pt from cache in 0.002807140350341797 \n",
      "ds: <datasets.PreprocessDataset object at 0x7f969482de48>\n",
      "4185\n",
      "normalized train!\n",
      "ds: <datasets.PreprocessDataset object at 0x7f969482db00>\n",
      "9185\n",
      "normalized test!\n",
      "normalized SUB dataset!\n",
      "loading dataset from 'd19t1_sub'\n",
      "ds: <datasets.PreprocessDataset object at 0x7f96951a8048>\n",
      "7200\n",
      "will load pre-trained model from  pretrained_models/single_resnet/last_model_300.pth\n"
     ]
    }
   ],
   "source": [
    "epochs = epochs\n",
    "trainer = Trainer(default_conf)\n",
    "if load is not None:\n",
    "    model_path = load\n",
    "    print(\"will load pre-trained model from \", model_path)\n",
    "    import torch\n",
    "    from datetime import datetime\n",
    "    checkpoint = torch.load(model_path)\n",
    "    try:\n",
    "        trainer.bare_model.load_state_dict(checkpoint['state_dict'])\n",
    "    except:\n",
    "        print(\"\\n\\nFailed: to load weights check that you have the correct rho value\\n\\n\")\n",
    "        raise\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded, predicting...\n",
      "type of model: <class 'models.cp_resnet.Network'>\n",
      "3566612\n",
      "self.dataloaders  {'testing': <torch.utils.data.dataloader.DataLoader object at 0x7f969482da90>, 'training': <torch.utils.data.dataloader.DataLoader object at 0x7f969482dcc0>, 'eval': <torch.utils.data.dataloader.DataLoader object at 0x7f96951a8080>}\n",
      "test loader: 7200\n",
      "x: torch.Size([10, 2, 256, 431])\n",
      "in_c: torch.Size([10, 128, 127, 215])\n",
      "stage1: torch.Size([10, 128, 15, 26])\n",
      "stage2: torch.Size([10, 256, 15, 26])\n",
      "stage3: torch.Size([10, 512, 15, 26])\n",
      "feed_forward: torch.Size([10, 10, 1, 1])\n",
      "logit: torch.Size([10, 10])\n",
      "tensor([[-0.5738, -1.2893, -2.1230, -0.5314,  6.8445, -0.2276, -1.2672, -0.5017,\n",
      "         -0.6864, -1.6717],\n",
      "        [-1.5723,  0.9029,  1.1515, -1.1577, -2.4846,  0.8643, -2.5983, -1.7137,\n",
      "         -0.8663,  4.1033],\n",
      "        [-0.5631, -2.8480, -2.3224, -0.4058, -2.8077, -0.5305,  3.4302,  0.1361,\n",
      "         -1.8396, -3.3523],\n",
      "        [ 0.2794, -2.7340, -2.7687, -2.9684, -1.8256,  4.6793,  0.6823,  2.7914,\n",
      "         -0.7829, -2.7966],\n",
      "        [-0.5153, -0.9763, -1.5568, -1.0611, -2.5188,  0.5643,  4.8275,  1.5640,\n",
      "         -0.9884, -2.1329],\n",
      "        [-0.3084,  5.5198,  0.3367, -0.8842, -0.7116, -0.7679, -1.7159, -0.8041,\n",
      "         -0.7744,  4.3596],\n",
      "        [-1.2348,  2.1968,  2.7632, -0.9263, -1.4181, -1.3764, -2.0100, -2.2635,\n",
      "         -0.1393,  4.5254],\n",
      "        [-0.1566, -2.4881, -2.1682,  0.1562, -2.8326, -0.9889,  6.1293, -1.4872,\n",
      "         -1.9514, -3.1724],\n",
      "        [-0.9897, -1.6927, -1.4867, -2.0323,  0.4726,  1.5839, -3.1209, -0.1087,\n",
      "          5.6446, -1.9063],\n",
      "        [-1.8985,  0.2884,  0.1469,  7.0998, -1.8076, -1.3853, -2.2103, -2.7573,\n",
      "         -0.1865, -0.7748]], device='cuda:0')\n",
      "tensor([[5.9764e-04, 2.9221e-04, 1.2696e-04, 6.2353e-04, 9.9584e-01, 8.4487e-04,\n",
      "         2.9876e-04, 6.4231e-04, 5.3402e-04, 1.9935e-04],\n",
      "        [2.9727e-03, 3.5327e-02, 4.5297e-02, 4.5000e-03, 1.1938e-03, 3.3990e-02,\n",
      "         1.0655e-03, 2.5806e-03, 6.0225e-03, 8.6705e-01],\n",
      "        [1.6620e-02, 1.6918e-03, 2.8613e-03, 1.9451e-02, 1.7612e-03, 1.7171e-02,\n",
      "         9.0134e-01, 3.3442e-02, 4.6371e-03, 1.0217e-03],\n",
      "        [1.0317e-02, 5.0685e-04, 4.8954e-04, 4.0095e-04, 1.2572e-03, 8.4033e-01,\n",
      "         1.5437e-02, 1.2722e-01, 3.5662e-03, 4.7609e-04],\n",
      "        [4.4731e-03, 2.8210e-03, 1.5787e-03, 2.5916e-03, 6.0322e-04, 1.3166e-02,\n",
      "         9.3531e-01, 3.5780e-02, 2.7869e-03, 8.8734e-04],\n",
      "        [2.2100e-03, 7.5085e-01, 4.2130e-03, 1.2426e-03, 1.4767e-03, 1.3959e-03,\n",
      "         5.4095e-04, 1.3462e-03, 1.3868e-03, 2.3534e-01],\n",
      "        [2.4349e-03, 7.5306e-02, 1.3267e-01, 3.3150e-03, 2.0271e-03, 2.1135e-03,\n",
      "         1.1215e-03, 8.7040e-04, 7.2825e-03, 7.7286e-01],\n",
      "        [1.8501e-03, 1.7974e-04, 2.4748e-04, 2.5294e-03, 1.2735e-04, 8.0488e-04,\n",
      "         9.9337e-01, 4.8898e-04, 3.0740e-04, 9.0660e-05],\n",
      "        [1.2762e-03, 6.3184e-04, 7.7640e-04, 4.4990e-04, 5.5081e-03, 1.6735e-02,\n",
      "         1.5147e-04, 3.0799e-03, 9.7088e-01, 5.1032e-04],\n",
      "        [1.2316e-04, 1.0970e-03, 9.5233e-04, 9.9628e-01, 1.3488e-04, 2.0575e-04,\n",
      "         9.0172e-05, 5.2182e-05, 6.8230e-04, 3.7885e-04]], device='cuda:0')\n",
      "tensor([[-0.5738, -1.2893, -2.1230, -0.5314,  6.8445, -0.2276, -1.2672, -0.5017,\n",
      "         -0.6864, -1.6717],\n",
      "        [-1.5723,  0.9029,  1.1515, -1.1577, -2.4846,  0.8643, -2.5983, -1.7137,\n",
      "         -0.8663,  4.1033],\n",
      "        [-0.5631, -2.8480, -2.3224, -0.4058, -2.8077, -0.5305,  3.4302,  0.1361,\n",
      "         -1.8396, -3.3523],\n",
      "        [ 0.2794, -2.7340, -2.7687, -2.9684, -1.8256,  4.6793,  0.6823,  2.7914,\n",
      "         -0.7829, -2.7966],\n",
      "        [-0.5153, -0.9763, -1.5568, -1.0611, -2.5188,  0.5643,  4.8275,  1.5640,\n",
      "         -0.9884, -2.1329],\n",
      "        [-0.3084,  5.5198,  0.3367, -0.8842, -0.7116, -0.7679, -1.7159, -0.8041,\n",
      "         -0.7744,  4.3596],\n",
      "        [-1.2348,  2.1968,  2.7632, -0.9263, -1.4181, -1.3764, -2.0100, -2.2635,\n",
      "         -0.1393,  4.5254],\n",
      "        [-0.1566, -2.4881, -2.1682,  0.1562, -2.8326, -0.9889,  6.1293, -1.4872,\n",
      "         -1.9514, -3.1724],\n",
      "        [-0.9897, -1.6927, -1.4867, -2.0323,  0.4726,  1.5839, -3.1209, -0.1087,\n",
      "          5.6446, -1.9063],\n",
      "        [-1.8985,  0.2884,  0.1469,  7.0998, -1.8076, -1.3853, -2.2103, -2.7573,\n",
      "         -0.1865, -0.7748]])\n",
      "sids: ['audio/0.wav', 'audio/1.wav', 'audio/2.wav', 'audio/3.wav', 'audio/4.wav', 'audio/5.wav', 'audio/6.wav', 'audio/7.wav', 'audio/8.wav', 'audio/9.wav']\n",
      "57.61091709136963Step 649/720 \n",
      "audio/0.wav\n",
      "tensor([-0.5738, -1.2893, -2.1230, -0.5314,  6.8445, -0.2276, -1.2672, -0.5017,\n",
      "        -0.6864, -1.6717])\n",
      "sids: 7200 torch.Size([7200, 10])\n"
     ]
    }
   ],
   "source": [
    "if load is not None:\n",
    "    print(\"model loaded, predicting...\")\n",
    "    sids, propbs = trainer.do_predict(\"eval\",{})\n",
    "    print(sids[0])\n",
    "    print(propbs[0])\n",
    "    print(\"sids:\",len(sids),propbs.shape)\n",
    "    torch.save((sids, propbs),str(datetime.now())+\"eval_predictions.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# else:\n",
    "#     trainer.fit(epochs)\n",
    "#     trainer.predict(\"last\")\n",
    "#     trainer.load_best_model()\n",
    "#     trainer.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpjku_dcase19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
